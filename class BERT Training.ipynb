{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext import data\n",
    "\n",
    "# assorted QOL things\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# my classes\n",
    "from langhelper import BERTHelper\n",
    "from classifier import *\n",
    "import modelfitting\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lang_helper = BERTHelper('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = lang_helper.max_tokens\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define text/label data types, used for when we instantiate the torchtext TabularDataset class\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = lang_helper.tokenize_and_cut,\n",
    "                  preprocessing = lang_helper.bert_tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = lang_helper.bert_tokenizer.cls_token_id,\n",
    "                  eos_token = lang_helper.bert_tokenizer.sep_token_id,\n",
    "                  pad_token = lang_helper.bert_tokenizer.pad_token_id,\n",
    "                  unk_token = lang_helper.bert_tokenizer.unk_token_id)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data, apply TEXT/LABEL data types to the 'headline'/'is_sarcastic' fields (respectively, and create train and test datasets. Tochtext is pretty good!\n",
    "headlines_train, headlines_test = data.TabularDataset(\n",
    "    path='./data/Sarcasm_Headlines_Dataset_v2.json', format='json',\n",
    "    fields={'headline': ('text', TEXT),\n",
    "            'is_sarcastic': ('label', LABEL)}).split(split_ratio=0.85, random_state = random.seed(1234))\n",
    "\n",
    "# split train dataset into train + validation\n",
    "headlines_train, headlines_valid = headlines_train.split(random_state = random.seed(1234))\n",
    "print(vars(headlines_train.examples[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the data objects we just created we instantiate the bucketiterator class, which is the last preprocessing step we'll take with the data.\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (headlines_train, headlines_valid, headlines_test), \n",
    "    batch_size = 16,\n",
    "    sort_key=lambda x: len(x.text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "    sort_within_batch=False,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                 bert_helper,\n",
    "                 hidden_dim,\n",
    "                 l1_dim,\n",
    "                 l2_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our model\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.40\n",
    "model = BERTGRUSentimentPerc(lang_helper,\n",
    "                             HIDDEN_DIM,\n",
    "                             100,\n",
    "                             50,\n",
    "                             OUTPUT_DIM,\n",
    "                             N_LAYERS,\n",
    "                             DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use Adam for optimization, and our loss function will be BCE with logit loss\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=40\n",
    "\n",
    "modelfitting.fit(n_epochs=N, model=model, train_iter=train_iterator, valid_iter=valid_iterator, optimizer=optimizer, criterion=criterion, model_name='GRU perceptron 040 drop 3 layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's test out a few sample headlines:\n",
    "# sarcastic one from the onion, 5/10/2020 (https://www.theonion.com/experts-warn-unemployment-rate-could-soon-rise-to-ameri-1843348378)\n",
    "print(single_eval(model, 'Experts Warn Unemployment Rate Could Soon Rise To America Is The Greatest Country In The World', lang_helper, device))\n",
    "\n",
    "# real one from NPR, 5/10/2020 (https://www.npr.org/2020/05/10/852943513/the-people-flying-during-the-pandemic-and-how-airlines-are-trying-to-protect-the)\n",
    "print(single_eval(model, 'The People Flying During The Pandemic And How Airlines Are Trying To Protect Them', lang_helper, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('GRU 040 drop 3 layer.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does it look on our test dataset?\n",
    "test_loss, test_acc, test_precision, test_recall, test_f1 = modelfitting.evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss :.3f} | Test Acc: {test_acc*100 :.2f}')\n",
    "print(f'Test Precision: {test_precision :.3f} | Test Recall: {test_recall*100 :.2f} | Test F1: {test_f1*100 :.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 90% accuracy on the test set. Not too bad considering most of the Kaggle front page solutions have validation set accuracies in the mid 80s!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
